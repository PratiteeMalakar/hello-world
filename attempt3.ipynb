{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFPLy8AH9GBiYi7TvBwQSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratiteeMalakar/hello-world/blob/main/attempt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gEyerg-WzT-I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define synthetic data generators\n",
        "def generate_sales_data():\n",
        "    dates = pd.date_range(start='2023-01-01', periods=365, freq='D')\n",
        "    products = ['Product A', 'Product B', 'Product C']\n",
        "    data = {\n",
        "        'date': np.tile(dates, len(products)),\n",
        "        'product': np.repeat(products, len(dates)),\n",
        "        'sales': np.random.randint(50, 500, size=len(dates) * len(products))\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_inventory_data():\n",
        "    products = ['Product A', 'Product B', 'Product C']\n",
        "    dates = pd.date_range(start='2023-01-01', periods=365, freq='D')\n",
        "    data = {\n",
        "        'date': np.tile(dates, len(products)),\n",
        "        'product': np.repeat(products, len(dates)),\n",
        "        'inventory_level': np.random.randint(100, 1000, size=len(dates) * len(products))\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_supplier_data():\n",
        "    suppliers = ['Supplier X', 'Supplier Y', 'Supplier Z']\n",
        "    data = {\n",
        "        'supplier': suppliers,\n",
        "        'cost': [100, 150, 200],\n",
        "        'delivery_time': [5, 7, 3]  # in days\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_logistics_data():\n",
        "    routes = ['Route 1', 'Route 2', 'Route 3']\n",
        "    data = {\n",
        "        'route': routes,\n",
        "        'delivery_time': [3, 5, 4]  # in days\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Generate and save data\n",
        "sales_data = generate_sales_data()\n",
        "inventory_data = generate_inventory_data()\n",
        "supplier_data = generate_supplier_data()\n",
        "logistics_data = generate_logistics_data()\n",
        "\n",
        "sales_data.to_csv('sales_data.csv', index=False)\n",
        "inventory_data.to_csv('inventory_data.csv', index=False)\n",
        "supplier_data.to_csv('supplier_data.csv', index=False)\n",
        "logistics_data.to_csv('logistics_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load and prepare data\n",
        "sales_data = pd.read_csv('sales_data.csv')\n",
        "\n",
        "def prepare_data(data, window_size=10):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    X, y = [], []\n",
        "    for i in range(len(scaled_data) - window_size):\n",
        "        X.append(scaled_data[i:i + window_size])\n",
        "        y.append(scaled_data[i + window_size])\n",
        "    return np.array(X), np.array(y), scaler\n",
        "\n",
        "X, y, scaler = prepare_data(sales_data[['sales']].values)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y, epochs=10, batch_size=32)\n",
        "model.save('demand_forecasting_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGIvy-HrzYww",
        "outputId": "4ad9a1b4-0861-4d71-e2f4-eed6df9d7d9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 0.1829\n",
            "Epoch 2/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0858\n",
            "Epoch 3/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0872\n",
            "Epoch 4/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0869\n",
            "Epoch 5/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0847\n",
            "Epoch 6/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0837\n",
            "Epoch 7/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0816\n",
            "Epoch 8/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0846\n",
            "Epoch 9/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0841\n",
            "Epoch 10/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_eoq(demand, order_cost, holding_cost):\n",
        "    \"\"\"\n",
        "    Calculate the Economic Order Quantity (EOQ).\n",
        "    \"\"\"\n",
        "    return np.sqrt((2 * demand * order_cost) / holding_cost)\n"
      ],
      "metadata": {
        "id": "ewUoIbSZzYzQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mistralai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxG4Bz4Pz3Oa",
        "outputId": "c87cfd6b-8fe0-4046-bcde-150a1b86f7d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-0.4.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting httpx<1,>=0.25 (from mistralai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting orjson<3.11,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.25->mistralai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.25->mistralai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.25->mistralai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.5.2->mistralai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.25->mistralai) (1.2.2)\n",
            "Downloading mistralai-0.4.2-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, h11, httpcore, httpx, mistralai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 mistralai-0.4.2 orjson-3.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up Mistral.ai API key\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get(\"MISTRAL\")  # Replace with your actual API key\n",
        "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "\n",
        "client = MistralClient(api_key=mistral_api_key)"
      ],
      "metadata": {
        "id": "Nat1Tdh5zY17"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate embeddings using Mistral.ai\n",
        "def generate_embeddings(text):\n",
        "    response = client.embeddings(\n",
        "        input=text,\n",
        "        model=\"mistral-embed\"  # Choose an appropriate model for your use case\n",
        "    )\n",
        "    return response.data[0].embedding\n"
      ],
      "metadata": {
        "id": "vpKIFF5wzY4X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_demand(product, product_data, window_size=10):\n",
        "    \"\"\"\n",
        "    Forecast demand for a specific product using the LSTM model.\n",
        "    \"\"\"\n",
        "    product_sales = product_data[product_data['product'] == product]['sales'].values\n",
        "    X, _, scaler = prepare_data(product_sales, window_size)\n",
        "\n",
        "    last_window = X[-1].reshape(1, window_size, 1)\n",
        "    forecast_scaled = lstm_model.predict(last_window)\n",
        "    forecast = scaler.inverse_transform(forecast_scaled).flatten()[0]\n",
        "\n",
        "    return f\"The projected demand for {product} is {forecast:.2f} units.\"\n"
      ],
      "metadata": {
        "id": "V4lTy45VzY7N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_inventory(product, demand, order_cost, holding_cost):\n",
        "    \"\"\"\n",
        "    Calculate the optimal inventory level for a given product.\n",
        "    \"\"\"\n",
        "    eoq = calculate_eoq(demand, order_cost, holding_cost)\n",
        "    return f\"The optimal inventory level for {product} is {eoq:.2f} units.\"\n"
      ],
      "metadata": {
        "id": "1EfJFLj0zY95"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Example knowledge base or pre-defined responses\n",
        "knowledge_base = {\n",
        "    \"Product A demand forecast\": \"The projected demand for Product A is 1500 units.\",\n",
        "    \"Product B demand forecast\": \"The projected demand for Product B is 1200 units.\",\n",
        "    \"Product A inventory level\": \"The optimal inventory level for Product A is 500 units.\",\n",
        "    \"Product B inventory level\": \"The optimal inventory level for Product B is 600 units.\"\n",
        "}\n",
        "\n",
        "def handle_query(query):\n",
        "    \"\"\"\n",
        "    Process user queries using embeddings from Mistral.ai.\n",
        "    \"\"\"\n",
        "    # Generate embedding for the user query\n",
        "    query_embedding = generate_embeddings(query)\n",
        "\n",
        "    # Generate embeddings for each pre-defined response\n",
        "    responses = list(knowledge_base.keys())\n",
        "    response_embeddings = [generate_embeddings(resp) for resp in responses]\n",
        "\n",
        "    # Calculate similarity between query and response embeddings\n",
        "    similarities = [cosine_similarity([query_embedding], [resp_emb])[0][0] for resp_emb in response_embeddings]\n",
        "\n",
        "    # Find the most similar response\n",
        "    most_similar_index = np.argmax(similarities)\n",
        "    best_response_key = responses[most_similar_index]\n",
        "\n",
        "    # Get the response from the knowledge base\n",
        "    response = knowledge_base[best_response_key]\n",
        "\n",
        "    return f\"Answer: {response}\"\n",
        "\n",
        "# Example user query\n",
        "query = \"What is the projected demand for Product A next month?\"\n",
        "print(handle_query(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLdR2cpKzZA6",
        "outputId": "ba7e9011-a598-4bc4-9225-4bebe9716a4b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The projected demand for Product A is 1500 units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qpy2Zg0hzZDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0gNny4s_zZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvATO-ZIzZI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kx_arRfvzZMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VPRAtCPzZOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5vFJAVmzZSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}